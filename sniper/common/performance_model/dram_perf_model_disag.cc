#include "dram_perf_model_disagg.h"
#include "simulator.h"
#include "config.h"
#include "config.hpp"
#include "stats.h"
#include "shmem_perf.h"
#include "subsecond_time.h"
#include "utils.h"

//DramPerfModelDisagg::DramPerfModelDisagg(String name, core_id_t core_id, AddressHomeLookup* address_home_lookup, UInt32 cache_block_size, ParametricDramDirectoryMSI::MemoryManager* memory_manager)
// Removing memory_manager since its kinda hard to implement and hence commenting out the TLB effects as well... didn't
// see any effect after all
DramPerfModelDisagg::DramPerfModelDisagg(core_id_t core_id, UInt32 cache_block_size, AddressHomeLookup* address_home_lookup)
   : DramPerfModel(core_id, cache_block_size)
   , m_core_id(core_id)
   , m_address_home_lookup(address_home_lookup)
//   , m_memory_manager(memory_manager)
   , m_num_banks           (Sim()->getCfg()->getInt("perf_model/dram/ddr/num_banks"))
   , m_num_banks_log2      (floorLog2(m_num_banks))
   , m_num_bank_groups     (Sim()->getCfg()->getInt("perf_model/dram/ddr/num_bank_groups"))
   , m_num_ranks           (Sim()->getCfg()->getInt("perf_model/dram/ddr/num_ranks"))
   , m_rank_offset         (Sim()->getCfg()->getInt("perf_model/dram/ddr/rank_offset"))
   , m_num_channels        (Sim()->getCfg()->getInt("perf_model/dram/ddr/num_channels"))
   , m_channel_offset      (Sim()->getCfg()->getInt("perf_model/dram/ddr/channel_offset"))
   , m_home_lookup_bit     (Sim()->getCfg()->getInt("perf_model/dram_directory/home_lookup_param"))
   , m_total_ranks         (m_num_ranks * m_num_channels)
   , m_banks_per_channel   (m_num_banks * m_num_ranks)
   , m_banks_per_bank_group (m_num_banks / m_num_bank_groups)
   , m_total_banks         (m_banks_per_channel * m_num_channels)
   , m_total_bank_groups   (m_num_bank_groups * m_num_ranks * m_num_channels)
   , m_data_bus_width      (Sim()->getCfg()->getInt("perf_model/dram/ddr/data_bus_width"))   // In bits
   , m_dram_speed          (Sim()->getCfg()->getInt("perf_model/dram/ddr/dram_speed"))       // In MHz
   , m_dram_page_size      (Sim()->getCfg()->getInt("perf_model/dram/ddr/dram_page_size"))
   , m_dram_page_size_log2 (floorLog2(m_dram_page_size))
   , m_open_page_mapping   (Sim()->getCfg()->getBool("perf_model/dram/ddr/open_page_mapping"))
   , m_column_offset       (Sim()->getCfg()->getInt("perf_model/dram/ddr/column_offset"))
   , m_column_hi_offset    (m_dram_page_size_log2 - m_column_offset + m_num_banks_log2) // Offset for higher order column bits
   , m_bank_offset         (m_dram_page_size_log2 - m_column_offset) // Offset for bank bits
   , m_randomize_address   (Sim()->getCfg()->getBool("perf_model/dram/ddr/randomize_address"))
   , m_randomize_offset    (Sim()->getCfg()->getInt("perf_model/dram/ddr/randomize_offset"))
   , m_column_bits_shift   (Sim()->getCfg()->getInt("perf_model/dram/ddr/column_bits_shift"))
   , m_bus_bandwidth       (m_dram_speed * m_data_bus_width / 1000) // In bits/ns: MT/s=transfers/us * bits/transfer
   , m_bank_keep_open      (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/bank_keep_open")))
   , m_bank_open_delay     (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/bank_open_delay")))
   , m_bank_close_delay    (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/bank_close_delay")))
   , m_dram_access_cost    (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/access_cost")))
   , m_intercommand_delay  (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/intercommand_delay")))
   , m_intercommand_delay_short  (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/intercommand_delay_short")))
   , m_intercommand_delay_long  (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/intercommand_delay_long")))
   , m_controller_delay    (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/controller_delay")))
   , m_refresh_interval    (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/refresh_interval")))
   , m_refresh_length      (SubsecondTime::NS() * static_cast<uint64_t> (Sim()->getCfg()->getFloat("perf_model/dram/ddr/refresh_length")))
   , m_localdram_size       (Sim()->getCfg()->getInt("perf_model/dram/localdram_size"))// Move data if greater than
   , m_banks               (m_total_banks)
   , m_page_hits           (0)
   , m_page_empty          (0)
   , m_page_closing        (0)
   , m_page_miss           (0)
   , m_data_moves           (0)
   , m_page_prefetches           (0)
   , m_inflight_hits           (0)
   , m_writeback_pages           (0)
   , m_local_evictions           (0)
   , m_extra_pages           (0)
   , m_redundant_moves           (0)
   , m_max_bufferspace           (0)
   , m_page_conflict_data_to_metadata(0)
   , m_page_conflict_metadata_to_data(0)
   , m_page_conflict_metadata_to_metadata(0)
   , m_page_conflict_data_to_data(0)
   , constant_time_policy(Sim()->getCfg()->getBool("perf_model/dram/ddr/constant_time_policy"))
   , selective_constant_time_policy(Sim()->getCfg()->getBool("perf_model/dram/ddr/selective_constant_time_policy"))
   , open_row_policy(Sim()->getCfg()->getBool("perf_model/dram/ddr/open_row_policy"))
   , m_total_queueing_delay(SubsecondTime::Zero())
   , m_total_access_latency(SubsecondTime::Zero())
 {
    
     String name("dram"); 
   if (Sim()->getCfg()->getBool("perf_model/dram/queue_model/enabled"))
   {

      for(UInt32 channel = 0; channel < m_num_channels; ++channel) {
         
         m_queue_model.push_back(QueueModel::create(
            name + "-queue-" + itostr(channel), core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
            m_bus_bandwidth.getRoundedLatency(8))); // bytes to bits
         // m_r_queue_model.push_back(QueueModel::create(
         //    name + "-remote-queue-" + itostr(channel), core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
         //    m_bus_bandwidth.getRoundedLatency(8))); // bytes to bits
      } 
      
   }
   // if(Sim()->getCfg()->getInt("perf_model/dram/remote_partitioned_queues") == 1) {
   //   m_data_movement = QueueModel::create(
   //          name + "-datamovement-queue", core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
   //          m_r_part_bandwidth.getRoundedLatency(8)); // bytes to bits
   //   m_data_movement_2 = QueueModel::create(
   //          name + "-datamovement-queue-2", core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
   //          m_r_part2_bandwidth.getRoundedLatency(8)); // bytes to bits
	// }
	// else {
   //   m_data_movement = QueueModel::create(
   //          name + "-datamovement-queue", core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
   //          m_r_bus_bandwidth.getRoundedLatency(8)); // bytes to bits
   //   m_data_movement_2 = QueueModel::create(
   //          name + "-datamovement-queue-2", core_id, Sim()->getCfg()->getString("perf_model/dram/queue_model/type"),
   //          m_r_bus_bandwidth.getRoundedLatency(8)); // bytes to bits	
	// }

   
   registerStatsMetric("dram", core_id, "total-access-latency", &m_total_access_latency); // cgiannoula
   for(UInt32 rank = 0; rank < m_total_ranks; ++rank) {
      m_rank_avail.push_back(QueueModel::create(
         name + "-rank-" + itostr(rank), core_id, "history_list",
         (m_num_bank_groups > 1) ? m_intercommand_delay_short : m_intercommand_delay));
      // m_r_rank_avail.push_back(QueueModel::create(
      //    name + "-remote-rank-" + itostr(rank), core_id, "history_list",
      //    (m_num_bank_groups > 1) ? m_intercommand_delay_short : m_intercommand_delay));
   }
   
   for(UInt32 group = 0; group < m_total_bank_groups; ++group) {
      m_bank_group_avail.push_back(QueueModel::create(
         name + "-bank-group-" + itostr(group), core_id, "history_list",
         m_intercommand_delay_long));
      // m_r_bank_group_avail.push_back(QueueModel::create(
      //    name + "-remote-bank-group-" + itostr(group), core_id, "history_list",
      //    m_intercommand_delay_long));
   }
   
   LOG_ASSERT_ERROR(cache_block_size == 64, "Hardcoded for 64-byte cache lines");
   LOG_ASSERT_ERROR(m_column_offset <= m_dram_page_size_log2, "Column offset exceeds bounds!");
   if(m_randomize_address)
      LOG_ASSERT_ERROR(m_num_bank_groups == 4 || m_num_bank_groups == 8, "Number of bank groups incorrect for address randomization!");
   
   registerStatsMetric("ddr", core_id, "page-hits", &m_page_hits);
   registerStatsMetric("ddr", core_id, "page-empty", &m_page_empty);
   registerStatsMetric("ddr", core_id, "page-closing", &m_page_closing);
   registerStatsMetric("ddr", core_id, "page-miss", &m_page_miss);
   registerStatsMetric("ddr", core_id, "page-conflict-data-to-metadata", &m_page_conflict_data_to_metadata);
   registerStatsMetric("ddr", core_id, "page-conflict-metadata-to-data", &m_page_conflict_metadata_to_data);
   registerStatsMetric("ddr", core_id, "page-conflict-metadata-to-metadata", &m_page_conflict_metadata_to_metadata);
   registerStatsMetric("ddr", core_id, "page-conflict-data-to-data", &m_page_conflict_data_to_data);
   registerStatsMetric("dram", core_id, "data-moves", &m_data_moves);
   registerStatsMetric("dram", core_id, "page-prefetches", &m_page_prefetches);
   registerStatsMetric("dram", core_id, "inflight-hits", &m_inflight_hits);
   registerStatsMetric("dram", core_id, "writeback-pages", &m_writeback_pages);
   registerStatsMetric("dram", core_id, "local-evictions", &m_local_evictions);
   registerStatsMetric("dram", core_id, "extra-traffic", &m_extra_pages);
   registerStatsMetric("dram", core_id, "redundant-moves", &m_redundant_moves);
   registerStatsMetric("dram", core_id, "max-bufferspace", &m_max_bufferspace);
   
}

DramPerfModelDisagg::~DramPerfModelDisagg()
{

   if (m_queue_model.size())
   {
      for(UInt32 channel = 0; channel < m_num_channels; ++channel)
         delete m_queue_model[channel];
   }
   if (m_rank_avail.size())
   {
      for(UInt32 rank = 0; rank < m_total_ranks; ++rank)
         delete m_rank_avail[rank];
   }

   if (m_bank_group_avail.size())
   {
      for(UInt32 group = 0; group < m_total_bank_groups; ++group)
         delete m_bank_group_avail[group];
   }
   
   // if (m_r_queue_model.size())
   // {
   //    for(UInt32 channel = 0; channel < m_num_channels; ++channel)
   //       delete m_r_queue_model[channel];
   // }

   // if (m_r_rank_avail.size())
   // {
   //    for(UInt32 rank = 0; rank < m_total_ranks; ++rank)
   //       delete m_r_rank_avail[rank];
   // }

   // if (m_r_bank_group_avail.size())
   // {
   //    for(UInt32 group = 0; group < m_total_bank_groups; ++group)
   //       delete m_r_bank_group_avail[group];
   // }
}

UInt64
DramPerfModelDisagg::parseAddressBits(UInt64 address, UInt32 &data, UInt32 offset, UInt32 size, UInt64 base_address = 0)
{
   //parse data from the address based on the offset and size, return the address without the bits used to parse the data.
   UInt32 log2_size = floorLog2(size);
   if (base_address != 0) {
      data = (base_address >> offset) % size;
   } else {
      data = (address >> offset) % size;
   }
   return ((address >> (offset + log2_size)) << offset) | (address & ((1 << offset) - 1));
}

void
DramPerfModelDisagg::parseDeviceAddress(IntPtr address, UInt32 &channel, UInt32 &rank, UInt32 &bank_group, UInt32 &bank, UInt32 &column, UInt64 &page)
{
   // Construct DDR address which has bits used for interleaving removed
   UInt64 linearAddress = m_address_home_lookup->getLinearAddress(address);
   UInt64 address_bits = linearAddress >> 6;
   /*address_bits = */parseAddressBits(address_bits, channel, m_channel_offset, m_num_channels, m_channel_offset < m_home_lookup_bit ? address : linearAddress);
   address_bits = parseAddressBits(address_bits, rank,    m_rank_offset,    m_num_ranks,    m_rank_offset < m_home_lookup_bit ? address : linearAddress);
   

   if (m_open_page_mapping)
   {
      // Open-page mapping: column address is bottom bits, then bank, then page
      if(m_column_offset)
      {
         // Column address is split into 2 halves ColHi and ColLo and
         // the address looks like: | Page | ColHi | Bank | ColLo |
         // m_column_offset specifies the number of ColHi bits
         column = (((address_bits >> m_column_hi_offset) << m_bank_offset)
               | (address_bits & ((1 << m_bank_offset) - 1))) % m_dram_page_size;
         address_bits = address_bits >> m_bank_offset;
         bank_group = address_bits % m_num_bank_groups;
         bank = address_bits % m_num_banks;
         address_bits = address_bits >> (m_num_banks_log2 + m_column_offset);
      }
      else
      {
         column = address_bits % m_dram_page_size; address_bits /= m_dram_page_size;
         bank_group = address_bits % m_num_bank_groups;
         bank = address_bits % m_num_banks; address_bits /= m_num_banks;
      }
      page = address_bits;

#if 0
      // Test address parsing done in this function for open page mapping
      std::bitset<10> bs_col (column);
      std::string str_col = bs_col.to_string<char,std::string::traits_type,std::string::allocator_type>();
      std::stringstream ss_original, ss_recomputed;
      ss_original << std::bitset<64>(linearAddress >> m_block_size_log2) << std::endl;
      ss_recomputed << std::bitset<50>(page) << str_col.substr(0,m_column_offset) << std::bitset<4>(bank)
         << str_col.substr(m_column_offset, str_col.length()-m_column_offset) << std::endl;
      LOG_ASSERT_ERROR(ss_original.str() == ss_recomputed.str(), "Error in device address parsing!");
#endif
   }
   else
   {
      bank_group = address_bits % m_num_bank_groups;
      bank = address_bits % m_num_banks;
      address_bits /= m_num_banks;

      // Closed-page mapping: column address is bits X+banksize:X, row address is everything else
      // (from whatever is left after cutting channel/rank/bank from the bottom)
      column = (address_bits >> m_column_bits_shift) % m_dram_page_size;
      page = (((address_bits >> m_column_bits_shift) / m_dram_page_size) << m_column_bits_shift)
           | (address_bits & ((1 << m_column_bits_shift) - 1));
   }

   if(m_randomize_address)
   {
      std::bitset<3> row_bits(page >> m_randomize_offset);                 // Row[offset+2:offset]
      UInt32 row_bits3 = row_bits.to_ulong();
      row_bits[2] = 0;
      UInt32 row_bits2 = row_bits.to_ulong();
      bank_group ^= ((m_num_bank_groups == 8) ? row_bits3 : row_bits2);    // BankGroup XOR Row
      bank /= m_num_bank_groups;
      bank ^= row_bits2;                                                   // Bank XOR Row
      bank = m_banks_per_bank_group * bank_group + bank;
      rank = (m_num_ranks > 1) ? rank ^ row_bits[0] : rank;                // Rank XOR Row
   }

   //printf("[%2d] address %12lx linearAddress %12lx channel %2x rank %2x bank_group %2x bank %2x page %8lx crb %4u\n", m_core_id, address, linearAddress, channel, rank, bank_group, bank, page, (((channel * m_num_ranks) + rank) * m_num_banks) + bank);
}

//SubsecondTime
//DramPerfModelDisagg::getAccessLatencyRemote(SubsecondTime pkt_time, UInt64 pkt_size, core_id_t requester, IntPtr address, DramCntlrInterface::access_t access_type, ShmemPerf *perf, SubsecondTime &queue_delay)
//Nandita: not sure if queue_delay is actually used anywhere so removing for now. May have to still update stats so the
//right ones are collected. 
// SubsecondTime
// DramPerfModelDisagg::getAccessLatencyRemote(SubsecondTime pkt_time, UInt64 pkt_size, core_id_t requester, IntPtr address, DramCntlrInterface::access_t access_type, ShmemPerf *perf)
// {
//    // pkt_size is in 'Bytes'
//    // m_dram_bandwidth is in 'Bits per clock cycle'

//    //std::cout << "Remote Access" << std::endl;

//    UInt32 channel, rank, bank_group, bank, column;
//    UInt64 page;
//    parseDeviceAddress(address, channel, rank, bank_group, bank, column, page);

//    SubsecondTime t_now = pkt_time;
//    perf->updateTime(t_now);

//    // DDR controller pipeline delay
//    t_now += m_controller_delay;
//    perf->updateTime(t_now, ShmemPerf::DRAM_CNTLR);

//    // DDR refresh
//    if (m_refresh_interval != SubsecondTime::Zero())
//    {
//       SubsecondTime refresh_base = (t_now.getPS() / m_refresh_interval.getPS()) * m_refresh_interval;
//       if (t_now - refresh_base < m_refresh_length)
//       {
//          t_now = refresh_base + m_refresh_length;
//          perf->updateTime(t_now, ShmemPerf::DRAM_REFRESH);
//       }
//    }

//    // Page hit/miss
//    UInt64 crb = (channel * m_num_ranks * m_num_banks) + (rank * m_num_banks) + bank; // Combine channel, rank, bank to index m_banks
//    LOG_ASSERT_ERROR(crb < m_total_banks, "Bank index out of bounds");
//    BankInfo &bank_info = m_r_banks[crb];

//    //printf("[%2d] %s (%12lx, %4lu, %4lu), t_open = %lu, t_now = %lu, bank_info.t_avail = %lu\n", m_core_id, bank_info.open_page == page && bank_info.t_avail + m_bank_keep_open >= t_now ? "Page Hit: " : "Page Miss:", address, crb, page % 10000, t_now.getNS() - bank_info.t_avail.getNS(), t_now.getNS(), bank_info.t_avail.getNS());
//    // Page hit/miss
//    if (bank_info.open_page == page                       // Last access was to this row
//       && bank_info.t_avail + m_bank_keep_open >= t_now   // Bank hasn't been closed in the meantime
//    )
//    {
//       if (bank_info.t_avail > t_now)
//       {
//          t_now = bank_info.t_avail;
//          perf->updateTime(t_now, ShmemPerf::DRAM_BANK_PENDING);
//       }
//       ++m_page_hits;
//    }
//    else
//    {
//       // Wait for bank to become available
//       if (bank_info.t_avail > t_now)
//          t_now = bank_info.t_avail;
//       // Close page
//       if (bank_info.t_avail + m_bank_keep_open >= t_now)
//       {
//          // We found the page open and have to close it ourselves
//          t_now += m_bank_close_delay;
//          ++m_page_miss;
//       }
//       else if (bank_info.t_avail + m_bank_keep_open + m_bank_close_delay > t_now)
//       {
//          // Bank was being closed, we have to wait for that to complete
//          t_now = bank_info.t_avail + m_bank_keep_open + m_bank_close_delay;
//          ++m_page_closing;
//       }
//       else
//       {
//          // Bank was already closed, no delay.
//          ++m_page_empty;
//       }

//       // Open page
//       t_now += m_bank_open_delay;
//       perf->updateTime(t_now, ShmemPerf::DRAM_BANK_CONFLICT);

//       bank_info.open_page = page;
//    }

//    // Rank access time and availability
//    UInt64 cr = (channel * m_num_ranks) + rank;
//    LOG_ASSERT_ERROR(cr < m_total_ranks, "Rank index out of bounds");
//    SubsecondTime rank_avail_request = (m_num_bank_groups > 1) ? m_intercommand_delay_short : m_intercommand_delay;
//    SubsecondTime rank_avail_delay = m_r_rank_avail.size() ? m_r_rank_avail[cr]->computeQueueDelay(t_now, rank_avail_request, requester) : SubsecondTime::Zero();

//    // Bank group access time and availability
//    UInt64 crbg = (channel * m_num_ranks * m_num_bank_groups) + (rank * m_num_bank_groups) + bank_group;
//    LOG_ASSERT_ERROR(crbg < m_total_bank_groups, "Bank-group index out of bounds");
//    SubsecondTime group_avail_delay = m_r_bank_group_avail.size() ? m_r_bank_group_avail[crbg]->computeQueueDelay(t_now, m_intercommand_delay_long, requester) : SubsecondTime::Zero();

//    // Device access time (tCAS)
//    t_now += m_dram_access_cost;
//    perf->updateTime(t_now, ShmemPerf::DRAM_DEVICE);

//    // Mark bank as busy until it can receive its next command
//    // Done before waiting for the bus to be free: sort of assumes best-case bus scheduling
//    bank_info.t_avail = t_now;

//    // Add the wait time for the larger of bank group and rank availability delay
//    t_now += (rank_avail_delay > group_avail_delay) ? rank_avail_delay : group_avail_delay;
//    perf->updateTime(t_now, ShmemPerf::DRAM_DEVICE);
//    //std::cout << "DDR Processing time: " << m_bus_bandwidth.getRoundedLatency(8*pkt_size) << std::endl; 

//    // DDR bus latency and queuing delay
//    SubsecondTime ddr_processing_time = m_bus_bandwidth.getRoundedLatency(8 * pkt_size); // bytes to bits
//    SubsecondTime ddr_queue_delay = m_r_queue_model.size() ? m_r_queue_model[channel]->computeQueueDelay(t_now, ddr_processing_time, requester) : SubsecondTime::Zero();
//    t_now += ddr_queue_delay;
//    perf->updateTime(t_now, ShmemPerf::DRAM_QUEUE);
//    //std::cout << "Local Queue Processing time: " << m_bus_bandwidth.getRoundedLatency(8*pkt_size) << " Local queue delay " << ddr_queue_delay << std::endl; 
//    SubsecondTime datamovement_queue_delay;
//    if(m_r_partition_queues == 1) { 
//    	datamovement_queue_delay = m_data_movement_2->computeQueueDelay(t_now, m_r_part2_bandwidth.getRoundedLatency(8*pkt_size), requester);
//         m_redundant_moves++; 
//    } 
//    else
//    	datamovement_queue_delay = m_data_movement->computeQueueDelay(t_now, m_r_bus_bandwidth.getRoundedLatency(8*pkt_size), requester);
//    //std::cout << "Packet size: " << pkt_size << "  Cacheline Processing time: " << m_r_bus_bandwidth.getRoundedLatency(8*pkt_size) << " Remote queue delay " << datamovement_queue_delay << std::endl; 
//    t_now += ddr_processing_time;
//    t_now += m_r_added_latency;
//    if(m_r_mode != 4 && !m_r_enable_selective_moves) {
//    	t_now += datamovement_queue_delay;
//    } 
   
//    perf->updateTime(t_now, ShmemPerf::DRAM_BUS);
   
//  //track access to page
//    UInt64 phys_page =  address & ~((UInt64(1) << 12) - 1); //Assuming 4K page
//    if(m_r_cacheline_gran) 
// 	phys_page =  address & ~((UInt64(1) << 6) - 1); //Assuming 4K page 
//    bool move_page = false; 
//    if(m_r_mode == 2) { //Only move pages when the page has been accessed remotely m_r_datamov_threshold times
//    auto it = m_remote_access_tracker.find(phys_page);
//    if (it != m_remote_access_tracker.end())
// 	m_remote_access_tracker[phys_page]++; 
//    else
// 	m_remote_access_tracker[phys_page] = 1;
//    if (m_remote_access_tracker[phys_page] > m_r_datamov_threshold)
// 	move_page = true;
//    } 
//    if(m_r_mode == 1 || m_r_mode==3) {
//         move_page = true; 
//    }
//    if((m_r_reserved_bufferspace > 0) && ((m_inflight_pages.size() + m_inflightevicted_pages.size())  >= (m_r_reserved_bufferspace/100)*m_localdram_size/4096))
// 	move_page = false;
//     //if (m_r_enable_selective_moves) {
// //	if(m_data_movement->isQueueFull())
// //		move_page = false;
//   // } 
      
//    //Adding data movement cost of the entire page for now (this just adds contention in the queue):
//    if (move_page) {
// 	++m_data_moves;
// 	SubsecondTime page_datamovement_queue_delay = SubsecondTime::Zero();
//         if(m_r_simulate_datamov_overhead && !m_r_cacheline_gran) { 
// 		//check if queue is full
// 		//if it is... wait.
// 		//to wait: t_now + window_size
// 		//try again
// 		if(m_r_partition_queues) {
// 			page_datamovement_queue_delay = m_data_movement->computeQueueDelay(t_now, m_r_part_bandwidth.getRoundedLatency(8*4096), requester);
// 			//for(int i=0; i<64; i++)
// 			//	page_datamovement_queue_delay += m_data_movement->computeQueueDelay(t_now, m_r_part_bandwidth.getRoundedLatency(8*pkt_size), requester);
// 		}
// 		else {
// 			page_datamovement_queue_delay = m_data_movement->computeQueueDelay(t_now, m_r_bus_bandwidth.getRoundedLatency(8*4096), requester);
// 			//for(int i=0; i<64; i++)
// 			//	page_datamovement_queue_delay += m_data_movement->computeQueueDelay(t_now, m_r_bus_bandwidth.getRoundedLatency(8*pkt_size), requester);
// 			//std::cout << "Page processing time: " << m_r_bus_bandwidth.getRoundedLatency(8*4096) << std::endl;  
// 			//std::cout << "Moving page: " << page_datamovement_queue_delay << " Moving cacheline: " << datamovement_queue_delay << std::endl; 
// 			t_now += page_datamovement_queue_delay;
// 			t_now -= datamovement_queue_delay;  
// 		}
// 		//std::cout << m_r_bus_bandwidth.getRoundedLatency(8*4096) << std::endl;  
// 	}
// 	else
// 		page_datamovement_queue_delay = SubsecondTime::Zero(); 
//         /* //Removing the TLB overhead part for now
//       if (m_r_simulate_tlb_overhead && std::find(m_memory_manager->m_invalid_PTE.begin(), m_memory_manager->m_invalid_PTE.end(), phys_page) == m_memory_manager->m_invalid_PTE.end())
// 	m_memory_manager->m_invalid_PTE.push_back(phys_page);
//     */ 
// 	//printf("Moving page: %lx\n", phys_page); 
//         assert(std::find(m_local_pages.begin(), m_local_pages.end(), phys_page) == m_local_pages.end()); 
//         assert(std::find(m_remote_pages.begin(), m_remote_pages.end(), phys_page) != m_remote_pages.end()); 
//         m_local_pages.push_back(phys_page);
// 	if(m_r_exclusive_cache)
//         	m_remote_pages.remove(phys_page);
// 	m_inflight_pages.erase(phys_page);
// 	//m_inflight_pages[phys_page] = std::max(Sim()->getClockSkewMinimizationServer()->getGlobalTime() + page_datamovement_queue_delay ,t_now + page_datamovement_queue_delay);
// 	m_inflight_pages[phys_page] = SubsecondTime::max(Sim()->getClockSkewMinimizationServer()->getGlobalTime() + page_datamovement_queue_delay ,t_now + page_datamovement_queue_delay);
// 	m_inflight_redundant[phys_page] = 0; 
// 	if(m_inflight_pages.size() > m_max_bufferspace)
// 		m_max_bufferspace++; 
//    } 
//    /* //Removing prefetches for now... Didn't really work anyway
//    if (m_r_mode==3) {
// 	while(!m_memory_manager->getMMU()->m_pages_to_prefetch.empty()) {
// 	phys_page = m_memory_manager->getMMU()->m_pages_to_prefetch.front();
// 	m_memory_manager->getMMU()->m_pages_to_prefetch.pop_front();
//         if(std::find(m_local_pages.begin(), m_local_pages.end(), phys_page) != m_local_pages.end())
// 		break; 
// 	++m_data_moves;
// 	++m_page_prefetches;
//         if(m_r_simulate_datamov_overhead) 
// 		SubsecondTime page_datamovement_queue_delay = m_data_movement->computeQueueDelay(t_now, m_r_bus_bandwidth.getRoundedLatency(8*4096), requester);
//       if (m_r_simulate_tlb_overhead && std::find(m_memory_manager->m_invalid_PTE.begin(), m_memory_manager->m_invalid_PTE.end(), phys_page) == m_memory_manager->m_invalid_PTE.end())
// 	m_memory_manager->m_invalid_PTE.push_back(phys_page);
// 	//printf("Moving page: %lx\n", phys_page); 
//         assert(std::find(m_local_pages.begin(), m_local_pages.end(), phys_page) == m_local_pages.end()); 
//         //assert(std::find(m_remote_pages.begin(), m_remote_pages.end(), phys_page) != m_remote_pages.end()); 
//         m_local_pages.push_back(phys_page);
//         m_remote_pages.remove(phys_page); 
// 	}
//    } */ 
//    if(move_page) { //Check if there's place in local DRAM and if not evict an older page to make space
// 	t_now += possiblyEvict(phys_page, pkt_time, requester);
//    }

//    // Update Memory Counters -- Nandita: Removing for now as I'm not sure that it's really used anywhere
//    //queue_delay = ddr_queue_delay;

//    //CLear prefetcher
//    /* //PUt back when you want prefetcher enabled
//    m_memory_manager->getMMU()->m_pages_to_prefetch.clear(); 
//    */ 
//    //std::cout << "Remote Latency: " << t_now - pkt_time << std::endl;
//    possiblyPrefetch(phys_page, t_now, requester);
//    return t_now - pkt_time;
// }


//Nandita: not sure if queue_delay is actually used anywhere so removing for now. May have to still update stats so the
//right ones are collected. 
//SubsecondTime
//DramPerfModelDisagg::getAccessLatency(SubsecondTime pkt_time, UInt64 pkt_size, core_id_t requester, IntPtr address, DramCntlrInterface::access_t access_type, ShmemPerf *perf, SubsecondTime &queue_delay)
SubsecondTime
DramPerfModelDisagg::getAccessLatency(SubsecondTime pkt_time, UInt64 pkt_size, core_id_t requester, IntPtr address, DramCntlrInterface::access_t access_type, ShmemPerf *perf,bool is_metadata)
{
   UInt64 phys_page =  address & ~((UInt64(1) << 12) - 1); //Assuming 4K page 
   // if(m_r_cacheline_gran) 
	// phys_page =  address & ~((UInt64(1) << 6) - 1); //Assuming 4K page 
   UInt64 cacheline =  address & ~((UInt64(1) << 6) - 1); //Assuming 4K page 
   //std::cout << "................................................................................" << std::endl;
   //std::cout << "Global: " << Sim()->getClockSkewMinimizationServer()->getGlobalTime() << " Now: " << pkt_time << " Page: " << std::hex << phys_page << " Cacheline: " << std::hex << cacheline << std::endl;
 
    std::map<UInt64, SubsecondTime>::iterator i;
    SubsecondTime max=SubsecondTime::Zero();
       if(Sim()->getClockSkewMinimizationServer()->getGlobalTime()>pkt_time){
          max=Sim()->getClockSkewMinimizationServer()->getGlobalTime();
       }
       else{
          max=pkt_time;
       }




   UInt32 channel, rank, bank_group, bank, column;
   UInt64 page;
   parseDeviceAddress(address, channel, rank, bank_group, bank, column, page);

	

   SubsecondTime t_now = pkt_time;
   perf->updateTime(t_now);

   // DDR controller pipeline delay
   t_now += m_controller_delay;
   perf->updateTime(t_now, ShmemPerf::DRAM_CNTLR);

   // DDR refresh
   if (m_refresh_interval != SubsecondTime::Zero())
   {
      SubsecondTime refresh_base = (t_now.getPS() / m_refresh_interval.getPS()) * m_refresh_interval;
      if (t_now - refresh_base < m_refresh_length)
      {
         t_now = refresh_base + m_refresh_length;
         perf->updateTime(t_now, ShmemPerf::DRAM_REFRESH);
      }
   }

   // Page hit/miss
   UInt64 crb = (channel * m_num_ranks * m_num_banks) + (rank * m_num_banks) + bank; // Combine channel, rank, bank to index m_banks
   LOG_ASSERT_ERROR(crb < m_total_banks, "Bank index out of bounds");
   BankInfo &bank_info = m_banks[crb];
   
   //printf("[%2d] %s (%12lx, %4lu, %4lu), t_open = %lu, t_now = %lu, bank_info.t_avail = %lu\n", m_core_id, bank_info.open_page == page && bank_info.t_avail + m_bank_keep_open >= t_now ? "Page Hit: " : "Page Miss:", address, crb, page % 10000, t_now.getNS() - bank_info.t_avail.getNS(), t_now.getNS(), bank_info.t_avail.getNS());
   // Page hit/miss
   if ((bank_info.open_page == page)                  // Last access was to this row
      && bank_info.t_avail + m_bank_keep_open >= t_now   // Bank hasn't been closed in the meantime
   )
   {
      if (bank_info.t_avail > t_now)
      {
         t_now = bank_info.t_avail;
         perf->updateTime(t_now, ShmemPerf::DRAM_BANK_PENDING);
      }
      if((bank_info.core_id != requester) && selective_constant_time_policy){
         t_now += m_bank_close_delay;  
         t_now += m_bank_open_delay;        
         perf->updateTime(t_now, ShmemPerf::DRAM_BANK_CONFLICT);

      }


      if(constant_time_policy){
         t_now += m_bank_close_delay;
         t_now += m_bank_open_delay;
         perf->updateTime(t_now, ShmemPerf::DRAM_BANK_CONFLICT);
      }

      ++m_page_hits;
   }
   else
   {
      // Wait for bank to become available
      if (bank_info.t_avail > t_now)
         t_now = bank_info.t_avail;
      // Close page
      if (bank_info.t_avail + m_bank_keep_open >= t_now)
      {
         if(bank_info.open_page_type == page_type::METADATA && !is_metadata){
            ++m_page_conflict_metadata_to_data;
            //std::cout<<"Page conflict md\n";
         }
         if(bank_info.open_page_type == page_type::NOT_METADATA && is_metadata){
            ++m_page_conflict_data_to_metadata;
            //std::cout<<"Page conflict dm\n";
         }
         if(bank_info.open_page_type == page_type::METADATA && is_metadata){
            ++m_page_conflict_metadata_to_metadata;
            //std::cout<<"Page conflict md\n";
         }
         if(bank_info.open_page_type == page_type::NOT_METADATA && !is_metadata){
            ++m_page_conflict_data_to_data;
            //std::cout<<"Page conflict dm\n";
         }
         t_now += m_bank_close_delay;
         ++m_page_miss;
      }
      else if (bank_info.t_avail + m_bank_keep_open + m_bank_close_delay > t_now)
      {
         // Bank was being closed, we have to wait for that to complete
         t_now = bank_info.t_avail + m_bank_keep_open +m_bank_close_delay;
         
         ++m_page_closing;
      }
      else 
      {
         // Bank was already closed, no delay.
         ++m_page_empty;
         if(constant_time_policy)
            t_now += m_bank_close_delay;
      }

      // Open page
      t_now += m_bank_open_delay;
      perf->updateTime(t_now, ShmemPerf::DRAM_BANK_CONFLICT);
      
      if(is_metadata){
         bank_info.open_page_type=page_type::METADATA;
      }
      else{
         bank_info.open_page_type=page_type::NOT_METADATA;
      }
      if(open_row_policy)
         bank_info.open_page = page;
      else 
         bank_info.open_page = 0;

   }
   bank_info.core_id = requester;
   // Rank access time and availability
   UInt64 cr = (channel * m_num_ranks) + rank;
   LOG_ASSERT_ERROR(cr < m_total_ranks, "Rank index out of bounds");
   SubsecondTime rank_avail_request = (m_num_bank_groups > 1) ? m_intercommand_delay_short : m_intercommand_delay;
   SubsecondTime rank_avail_delay = m_rank_avail.size() ? m_rank_avail[cr]->computeQueueDelay(t_now, rank_avail_request, requester) : SubsecondTime::Zero();

   // Bank group access time and availability
   UInt64 crbg = (channel * m_num_ranks * m_num_bank_groups) + (rank * m_num_bank_groups) + bank_group;
   LOG_ASSERT_ERROR(crbg < m_total_bank_groups, "Bank-group index out of bounds");
   SubsecondTime group_avail_delay = m_bank_group_avail.size() ? m_bank_group_avail[crbg]->computeQueueDelay(t_now, m_intercommand_delay_long, requester) : SubsecondTime::Zero();

   // Device access time (tCAS)
   t_now += m_dram_access_cost;
   perf->updateTime(t_now, ShmemPerf::DRAM_DEVICE);

   // Mark bank as busy until it can receive its next command
   // Done before waiting for the bus to be free: sort of assumes best-case bus scheduling
   bank_info.t_avail = t_now;

   // Add the wait time for the larger of bank group and rank availability delay
   t_now += (rank_avail_delay > group_avail_delay) ? rank_avail_delay : group_avail_delay;
   perf->updateTime(t_now, ShmemPerf::DRAM_DEVICE);

   // DDR bus latency and queuing delay
   SubsecondTime ddr_processing_time = m_bus_bandwidth.getRoundedLatency(8 * pkt_size); // bytes to bits
   //std::cout << m_bus_bandwidth.getRoundedLatency(8*pkt_size) << std::endl;  
   SubsecondTime ddr_queue_delay = m_queue_model.size() ? m_queue_model[channel]->computeQueueDelay(t_now, ddr_processing_time, requester) : SubsecondTime::Zero();
   t_now += ddr_queue_delay;
   perf->updateTime(t_now, ShmemPerf::DRAM_QUEUE);
   t_now += ddr_processing_time;
   perf->updateTime(t_now, ShmemPerf::DRAM_BUS);

   // Update Memory Counters -- Nandita:Removing this for now... not sure it's used anywhere
   //queue_delay = ddr_queue_delay;

   //std::cout << "Local Latency: " << t_now - pkt_time << std::endl; 

	//std::cout << "Result: Local" << std::endl;  
	return t_now - pkt_time;
   

 
   
}